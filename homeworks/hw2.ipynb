{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYp0bXOFK-hP"
   },
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "## Практическое задание 8. Метод опорных векторов и аппроксимация ядер\n",
    "\n",
    "### Общая информация\n",
    "Дата выдачи: 1.10.2021\n",
    "\n",
    "Мягкий дедлайн: 17.10.2021 23:59 МСК\n",
    "\n",
    "Жесткий дедлайн: 24.10.2021 23:59 МСК (1 неделя -- минус балл)\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимальная оценка за работу (без учёта бонусов) — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "### Формат сдачи\n",
    "Загрузите решение в свой репозиторий на github и поделитесь [ссылкой на решение в форме](https://forms.gle/ZzCaqRj6bmfpSpyL7). Не забудьте дать доступ к Вашему репозиторию, что у преподавателей была возмоожность проверить работу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY8vT0W_K-hR"
   },
   "source": [
    "### О задании\n",
    "\n",
    "На занятиях мы подробно обсуждали метод опорных векторов (SVM). В базовой версии в нём нет чего-то особенного — мы всего лишь используем специальную функцию потерь, которая не требует устремлять отступы к бесконечности; ей достаточно, чтобы отступы были не меньше +1. Затем мы узнали, что SVM можно переписать в двойственном виде, который, позволяет заменить скалярные произведения объектов на ядра. Это будет соответствовать построению модели в новом пространстве более высокой размерности, координаты которого представляют собой нелинейные модификации исходных признаков.\n",
    "\n",
    "Ядровой SVM, к сожалению, довольно затратен по памяти (нужно хранить матрицу Грама размера $d \\times d$) и по времени (нужно решать задачу условной оптимизации с квадратичной функцией, а это не очень быстро). Мы обсуждали, что есть способы посчитать новые признаки $\\tilde \\varphi(x)$ на основе исходных так, что скалярные произведения этих новых $\\langle \\tilde \\varphi(x), \\tilde \\varphi(z) \\rangle$ приближают ядро $K(x, z)$.\n",
    "\n",
    "Мы будем исследовать аппроксимации методом Random Fourier Features (RFF, также в литературе встречается название Random Kitchen Sinks) для гауссовых ядер. Будем использовать формулы, которые немного отличаются от того, что было на лекциях (мы добавим сдвиги внутрь тригонометрических функций и будем использовать только косинусы, потому что с нужным сдвигом косинус превратится в синус):\n",
    "$$\\tilde \\varphi(x) = (\n",
    "\\cos (w_1^T x + b_1),\n",
    "\\dots,\n",
    "\\cos (w_n^T x + b_n)\n",
    "),$$\n",
    "где $w_j \\sim \\mathcal{N}(0, 1/\\sigma^2)$, $b_j \\sim U[-\\pi, \\pi]$.\n",
    "\n",
    "На новых признаках $\\tilde \\varphi(x)$ мы будем строить любую линейную модель.\n",
    "\n",
    "Можно считать, что это некоторая новая парадигма построения сложных моделей. Можно направленно искать сложные нелинейные закономерности в данных с помощью градиентного бустинга или нейронных сетей, а можно просто нагенерировать большое количество случайных нелинейных признаков и надеяться, что быстрая и простая модель (то есть линейная) сможет показать на них хорошее качество. В этом задании мы изучим, насколько работоспособна такая идея.\n",
    "\n",
    "### Алгоритм\n",
    "\n",
    "Вам потребуется реализовать следующий алгоритм:\n",
    "1. Понизить размерность выборки до new_dim с помощью метода главных компонент.\n",
    "2. Для полученной выборки оценить гиперпараметр $\\sigma^2$ с помощью эвристики (рекомендуем считать медиану не по всем парам объектов, а по случайному подмножеству из где-то миллиона пар объектов): $$\\sigma^2 = \\text{median}_{i, j = 1, \\dots, \\ell, i \\neq j} \\left\\{\\sum_{k = 1}^{d} (x_{ik} - x_{jk})^2 \\right\\}$$\n",
    "3. Сгенерировать n_features наборов весов $w_j$ и сдвигов $b_j$.\n",
    "4. Сформировать n_features новых признаков по формулам, приведённым выше.\n",
    "5. Обучить линейную модель (логистическую регрессию или SVM) на новых признаках.\n",
    "6. Повторить преобразования (PCA, формирование новых признаков) к тестовой выборке и применить модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_sGunb7K-hS"
   },
   "source": [
    "Тестировать алгоритм мы будем на данных Fashion MNIST. Ниже код для их загрузки и подготовки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YyG6dBfjK-hS"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "(x_train_pics, y_train), (x_test_pics, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train_pics.reshape(y_train.shape[0], -1)\n",
    "x_test = x_test_pics.reshape(y_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJNN55F7K-hT"
   },
   "source": [
    "__Задание 1. (5 баллов)__\n",
    "\n",
    "Реализуйте алгоритм, описанный выше. Можете воспользоваться шаблоном класса ниже или написать свой интерфейс.\n",
    "\n",
    "Ваша реализация должна поддерживать следующие опции:\n",
    "1. Возможность задавать значения гиперпараметров new_dim (по умолчанию 50) и n_features (по умолчанию 1000).\n",
    "2. Возможность включать или выключать предварительное понижение размерности с помощью метода главных компонент.\n",
    "3. Возможность выбирать тип линейной модели (логистическая регрессия или SVM с линейным ядром).\n",
    "\n",
    "Протестируйте на данных Fashion MNIST, сформированных кодом выше. Если на тесте у вас получилась доля верных ответов не ниже 0.84 с гиперпараметрами по умолчанию, то вы всё сделали правильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "jP8yepx8K-hT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from types import MethodType\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "class RFFPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg'):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
    "        \n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.classifier = classifier\n",
    "        \n",
    "        self.pca = PCA(self.new_dim) if self.use_PCA else None\n",
    "        if self.classifier == \"logreg\":    \n",
    "            self.model = LogisticRegression(solver=\"sag\")\n",
    "        elif self.classifier == \"svm\":\n",
    "            self.model = SVC(kernel=\"linear\")\n",
    "        else:\n",
    "            raise ValueError(\"Incorrect classifier name. Must be 'logreg' or 'svm'.\"\n",
    "                             \" Passed '%s'\" % str(self.classifier))\n",
    "        self.sigma = None\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "        if self.use_PCA:\n",
    "            X = self.pca.fit_transform(X)\n",
    "        \n",
    "        else:\n",
    "            self.new_dim = X.shape[1]\n",
    "        \n",
    "        self.sigma = self._fit_sigma(X)\n",
    "        w, b = self._weights_sampler\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        X = self._rff(X)\n",
    "        \n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "        if self.use_PCA:\n",
    "            X = self.pca.transform(X)\n",
    "        X = self._rff(X)\n",
    "        return self.model.predict_proba(X)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        # Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "        if self.use_PCA:\n",
    "            X = self.pca.transform(X)\n",
    "        X = self._rff(X)\n",
    "        return self.model.predict(X)\n",
    "        \n",
    "    def _rff(self, X):\n",
    "        return np.cos(X @ self.w + self.b)\n",
    "    \n",
    "    @property\n",
    "    def _weights_sampler(self):\n",
    "        w = np.random.normal(\n",
    "            loc=0, scale=1 / self.sigma, \n",
    "            size=(self.new_dim, self.n_features)\n",
    "        )\n",
    "        b = np.random.uniform(\n",
    "            low=-np.pi, high=np.pi, size=(self.n_features)\n",
    "        )\n",
    "        return w, b\n",
    "    \n",
    "    def _fit_sigma(self, X):\n",
    "        pairs = self._random_pairs(X.shape[0], nsamp=1000000)\n",
    "        sigma = np.median(\n",
    "                    np.sum((X[pairs[0, :]] - X[pairs[1, :]])**2, axis=1)\n",
    "                )\n",
    "        # почему-то так оно работает, иначе - нет\n",
    "        # думаю дело в предобработке, которую PCA из sklearn делает под капотом\n",
    "        if self.use_PCA:\n",
    "            return np.sqrt(sigma)\n",
    "        else:\n",
    "            return sigma\n",
    "        \n",
    "    def _random_pairs(self, dim, nsamp=1000000):\n",
    "        x = np.random.choice(range(dim), size=nsamp)\n",
    "        y = np.random.choice(range(dim), size=nsamp)\n",
    "        pairs = np.concatenate((x[None, :], y[None, :]))\n",
    "        pairs = pairs[:, pairs[0, :] != pairs[1, :]]\n",
    "        return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\konqe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set = 0.8780\n",
      "Wall time: 6min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rff = RFFPipeline()\n",
    "rff.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rff.predict(x_test)\n",
    "print(\"Accuracy on test set = %.4f\" % (y_test == y_pred).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYqQUEi-K-hU"
   },
   "source": [
    "__Задание 2. (3 балла)__\n",
    "\n",
    "Сравните подход со случайными признаками с обучением SVM на исходных признаках. Попробуйте вариант с обычным (линейным) SVM и с ядровым SVM. Ядровой SVM может очень долго обучаться, поэтому можно делать любые разумные вещи для ускорения: брать подмножество объектов из обучающей выборки, например.\n",
    "\n",
    "Сравните подход со случайными признаками с вариантом, в котором вы понижаете размерность с помощью PCA и обучаете градиентный бустинг. Используйте одну из реализаций CatBoost/LightGBM/XGBoost, не забудьте подобрать число деревьев и длину шага.\n",
    "\n",
    "Сделайте выводы — насколько идея со случайными признаками работает? Сравните как с точки зрения качества, так и с точки зрения скорости обучения и применения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6000, 784), (6000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_subset, _, y_train_subset, _ = train_test_split(x_train, y_train, \n",
    "                                                  test_size=0.9, stratify=y_train, random_state=0)\n",
    "\n",
    "x_train_subset.shape, y_train_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qN8LUlJgK-hV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set = 0.7966\n",
      "Wall time: 54.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# тут тоже работало очень долго, если на всех объектах\n",
    "svm_lin = SVC(kernel=\"linear\")\n",
    "\n",
    "svm_lin.fit(x_train_subset, y_train_subset)\n",
    "\n",
    "y_pred = svm_lin.predict(x_test)\n",
    "print(\"Accuracy on test set = %.4f\" % (y_test == y_pred).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set = 0.8416\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm_rbf = SVC(kernel=\"rbf\")\n",
    "\n",
    "svm_rbf.fit(x_train_subset, y_train_subset)\n",
    "\n",
    "y_pred = svm_rbf.predict(x_test)\n",
    "print(\"Accuracy on test set = %.4f\" % (y_test == y_pred).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)\n",
    "x_train_pca = pca.fit_transform(x_train)\n",
    "x_test_pca = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set = 0.8707\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgbm = LGBMClassifier(n_estimators=1000,  learning_rate=1e-2)\n",
    "\n",
    "lgbm.fit(x_train_pca, y_train)\n",
    "\n",
    "y_pred = lgbm.predict(x_test_pca)\n",
    "print(\"Accuracy on test set = %.4f\" % (y_test == y_pred).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Выводы__:\n",
    "Линейный и ядровой SVM на всех объектах обучались очень долго (оставлял примерно на час каждый - без результатов). Получилось обучить только на одной десятой выборки - в принципе можно сказать, что для RBF ядра результаты сравнимы (учитывая, что объем выборки намного меньше), но и время обучения больше. Хотя в лоб сравнивать тоже не совсем правильно - все таки в RFF мы использовали PCA.\n",
    "\n",
    "Что качается бустинга + PCA - хочется сказать, что такой вариант выглядит получше - кач-во плюс минус такое же + работает быстрее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6umjhWuK-hV"
   },
   "source": [
    "__Задание 3. (2 балла)__\n",
    "\n",
    "Проведите эксперименты:\n",
    "1. Помогает ли предварительное понижение размерности с помощью PCA? \n",
    "2. Как зависит итоговое качество от n_features? Выходит ли оно на плато при росте n_features?\n",
    "3. Важно ли, какую модель обучать — логистическую регрессию или SVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "c2QIHIMbK-hW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\konqe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set = 0.8350\n",
      "Accuracy on train set = 0.8515\n",
      "Wall time: 3min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rff_no_pca = RFFPipeline(use_PCA=False)\n",
    "rff_no_pca.fit(x_train, y_train)\n",
    "\n",
    "print(\"Accuracy on test set = %.4f\" % (y_test == rff_no_pca.predict(x_test)).mean())\n",
    "print(\"Accuracy on train set = %.4f\" % (y_train == rff_no_pca.predict(x_train)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e4b809f62f4ee4a17dd91fbd8d7810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\konqe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\konqe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\konqe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\konqe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\konqe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 6min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "metrics = []\n",
    "\n",
    "for n_features in tqdm([100, 200, 300, 500, 800]):\n",
    "    rff_temp = RFFPipeline(n_features=n_features)\n",
    "    rff_temp.fit(x_train, y_train)\n",
    "    train_acc = (y_train == rff_temp.predict(x_train)).mean()\n",
    "    test_acc = (y_test == rff_temp.predict(x_test)).mean()\n",
    "    metrics.append((train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Качеств от n_features\")\n",
    "plt.plot([100, 200, 300, 500, 800], [metric[0] for metric in metrics], label=\"train\")\n",
    "plt.plot([100, 200, 300, 500, 800], [metric[1] for metric in metrics], label=\"val\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set = 0.8808\n",
      "Wall time: 13min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rff = RFFPipeline(classifier=\"svm\")\n",
    "rff.fit(x_train, y_train)\n",
    "\n",
    "y_pred = rff.predict(x_test)\n",
    "print(\"Accuracy on test set = %.4f\" % (y_test == y_pred).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Выводы__:\n",
    "1. В целом качество немного хуже (без PCA), так что считаем что PCA, по крайней мере в этой задаче, помогает\n",
    "1. В целом качество повышается и начинает выходить на плато - сходится к истинной оценке\n",
    "1. В этом примере особой разницы в метриках не наблюдается, только SVM обучается дольше. В принципе, ожидаемо по крайней мере для линейного ядра SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJqXVuasK-hW"
   },
   "source": [
    "### Бонус"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVDWHCdrK-hX"
   },
   "source": [
    "__Задание 4. (Максимум 2 балла)__\n",
    "\n",
    "Как вы, должно быть, помните с курса МО-1, многие алгоритмы машинного обучения работают лучше, если признаки данных некоррелированы. Оказывается, что для RFF существует модификация, позволяющая получать ортогональные случайные признаки (Orthogonal Random Features, ORF). Об этом методе можно прочитать в [статье](https://proceedings.neurips.cc/paper/2016/file/53adaf494dc89ef7196d73636eb2451b-Paper.pdf). Реализуйте класс для вычисления ORF по аналогии с основным заданием. Обратите внимание, что ваш класс должен уметь работать со случаем n_features > new_dim (в статье есть замечание на этот счет). Проведите эксперименты, сравнивающие RFF и ORF, сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "HSxvGI9iK-hX"
   },
   "outputs": [],
   "source": [
    "# Your code here: (￣▽￣)/♫•*¨*•.¸¸♪\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pc7-1jmK-hY"
   },
   "source": [
    "__Задание 5. (Максимум 2 балла)__\n",
    "\n",
    "Поэкспериментируйте с функциями для вычисления новых случайных признаков. Не обязательно использовать косинус от скалярного произведения — можно брать знак от него, хэш и т.д. Придумайте побольше вариантов для генерации признаков и проверьте, не получается ли с их помощью добиваться более высокого качества. Также можете попробовать другой классификатор поверх случайных признаков, сравните результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "dWj-O2vjK-hY"
   },
   "outputs": [],
   "source": [
    "def _rff_sign(self, X):\n",
    "    return np.sign(X @ self.w + self.b)\n",
    "    \n",
    "\n",
    "def _rff_sigmoid(self, X):\n",
    "    return 1 / (1 + np.exp(-(X @ self.w + self.b)))\n",
    "    \n",
    "\n",
    "def _rff(self, X):\n",
    "    return 1 / (1 + np.exp(-(X @ self.w + self.b)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\konqe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set = 0.8327\n",
      "Accuracy on train set = 0.8610\n"
     ]
    }
   ],
   "source": [
    "rff_sign = RFFPipeline()\n",
    "rff_sign._rff = MethodType(_rff_sign, rff_sign)\n",
    "\n",
    "rff_sign.fit(x_train, y_train)\n",
    "\n",
    "print(\"Accuracy on test set = %.4f\" % (y_test == rff_sign.predict(x_test)).mean())\n",
    "print(\"Accuracy on train set = %.4f\" % (y_train == rff_sign.predict(x_train)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\konqe\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set = 0.8572\n",
      "Accuracy on train set = 0.8725\n"
     ]
    }
   ],
   "source": [
    "rff_sigmoid = RFFPipeline()\n",
    "rff_sigmoid._rff = MethodType(_rff_sigmoid, rff_sigmoid)\n",
    "\n",
    "rff_sigmoid.fit(x_train, y_train)\n",
    "\n",
    "print(\"Accuracy on test set = %.4f\" % (y_test == rff_sigmoid.predict(x_test)).mean())\n",
    "print(\"Accuracy on train set = %.4f\" % (y_train == rff_sigmoid.predict(x_train)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set = 0.8609\n",
      "Accuracy on train set = 0.9993\n"
     ]
    }
   ],
   "source": [
    "rff_rfc = RFFPipeline()\n",
    "rff_rfc.model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rff_rfc.fit(x_train, y_train)\n",
    "\n",
    "print(\"Accuracy on test set = %.4f\" % (y_test == rff_rfc.predict(x_test)).mean())\n",
    "print(\"Accuracy on train set = %.4f\" % (y_train == rff_rfc.predict(x_train)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Вывод__:\n",
    "1. Попробовали - sign и sigmoid. В обоих случаях качество немного меньше, но сигмоида вроде получше\n",
    "1. Попробовали случайный лес - модель переобучилась. Но это дает надежду, что при определенных гиперпараметрах может получится что-то дельное."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework-practice-08-random-features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
